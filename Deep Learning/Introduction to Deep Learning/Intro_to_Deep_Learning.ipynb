{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-fEi11CNEXUL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fafc6e9-7e14-4cd2-c573-a771048765f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yfb30gU5L3YX",
        "outputId": "c0a7d17c-44f5-4eb5-b1d2-8b068a3c9115"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu = tf.config.list_physical_devices('GPU')[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "DUvUvjNgMaeJ",
        "outputId": "3ff9348c-c7ea-4f55-fdcb-652433b305cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d666324c16f4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a small part of the memory\n",
        "tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "HrMaQhnQL-IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Deep Learning"
      ],
      "metadata": {
        "id": "VDNh-bGWubAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "from sklearn.datasets import load_iris"
      ],
      "metadata": {
        "id": "HJiLs6LTLyKp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant(15)\n",
        "b = tf.constant(38)"
      ],
      "metadata": {
        "id": "p_O9rmBkTcT4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.pow(tf.add(tf.multiply(2, a), tf.multiply(3, b)), 2)"
      ],
      "metadata": {
        "id": "sV8f5-q6vfJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "755e8014-ea83-4abb-d6c5-c07bacf11992"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=20736>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([2, 15, 21, -244, 0, 4])\n",
        "b = tf.constant([3, 2, 20, 200, 18, 15])"
      ],
      "metadata": {
        "id": "NQdv5TeLvgKO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.pow(tf.add(tf.multiply(2, a), tf.multiply(3, b)), 2)"
      ],
      "metadata": {
        "id": "c-vUx0VrwV5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8bb30a-bafc-41cf-b301-7d7a38e234e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([  169,  1296, 10404, 12544,  2916,  2809], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(2 * a + 3 * b) ** 2"
      ],
      "metadata": {
        "id": "aGoVAWIqwXgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "853cbd44-83d5-4bb4-dfaa-c1d5563e45ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([  169,  1296, 10404, 12544,  2916,  2809], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.random.uniform([5, 8], 0, 20)\n",
        "b = tf.random.uniform([5, 8], 0, 20)"
      ],
      "metadata": {
        "id": "0CmpGqgjyj12"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b"
      ],
      "metadata": {
        "id": "KIHVSwRsytkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86202ffb-f477-4db6-db9b-008908a5cdd3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(5, 8), dtype=float32, numpy=\n",
              " array([[1.5221813e+01, 2.0042109e+00, 6.5647268e+00, 1.9273481e+01,\n",
              "         9.0476274e-01, 1.2093180e+01, 1.4590656e+01, 1.9586086e-02],\n",
              "        [1.3655753e+01, 5.9383202e+00, 8.0559616e+00, 1.1997046e+01,\n",
              "         1.7457006e+01, 1.8403912e+01, 8.6080980e+00, 9.8098660e+00],\n",
              "        [4.2902374e+00, 6.2112927e+00, 1.7076802e+00, 3.2944846e+00,\n",
              "         1.9365938e+01, 5.9847546e+00, 8.2594032e+00, 3.0208373e+00],\n",
              "        [1.9613987e+01, 1.6831190e+01, 1.9639757e+01, 1.6720343e+00,\n",
              "         1.7796612e+00, 1.2202423e+01, 1.5530588e+01, 1.6556668e+00],\n",
              "        [1.0033749e+01, 3.3072495e+00, 1.6065397e+01, 1.4599932e+01,\n",
              "         4.2684031e+00, 1.0820625e+01, 6.4506793e+00, 1.3848877e+00]],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 8), dtype=float32, numpy=\n",
              " array([[19.626034 ,  6.9214845,  7.9626107, 11.887409 , 19.332857 ,\n",
              "          2.996688 ,  4.836085 , 10.197971 ],\n",
              "        [11.540291 ,  0.6280136,  8.723452 ,  9.886492 ,  9.685483 ,\n",
              "         11.912937 ,  4.8635316,  7.8500223],\n",
              "        [18.727663 ,  8.675367 , 11.12668  , 19.62395  ,  4.3738747,\n",
              "          4.77123  ,  7.272923 , 11.945267 ],\n",
              "        [ 6.7248774,  9.408371 ,  7.9255247,  5.2411747, 13.961412 ,\n",
              "         15.667789 ,  9.307284 , 13.606976 ],\n",
              "        [11.313887 , 17.104464 ,  2.35636  , 15.8357315, 11.343843 ,\n",
              "         17.507233 ,  3.5745811,  5.8186746]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(2 * a + 3 * b) ** 2"
      ],
      "metadata": {
        "id": "CGUPDsoMy2rp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8a7d9c-9a86-4041-c41b-4fa11e509421"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 8), dtype=float32, numpy=\n",
              "array([[7978.3716 ,  613.69543, 1370.2797 , 5507.004  , 3577.0085 ,\n",
              "        1100.6749 , 1908.7783 ,  938.38605],\n",
              "       [3835.6199 ,  189.35635, 1787.7911 , 2878.7053 , 4092.2202 ,\n",
              "        5263.0137 , 1011.672  , 1863.6316 ],\n",
              "       [4194.3066 , 1478.3016 , 1353.9016 , 4285.118  , 2688.7854 ,\n",
              "         690.8066 , 1469.7699 , 1753.723  ],\n",
              "       [3528.6697 , 3830.0618 , 3976.07   ,  363.5731 , 2065.1172 ,\n",
              "        5099.134  , 3478.9976 , 1947.6562 ],\n",
              "       [2916.9888 , 3355.6406 , 1536.6302 , 5883.973  , 1812.0632 ,\n",
              "        5500.143  ,  558.1455 ,  409.08298]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare a function with tf\n",
        "@tf.function\n",
        "def compute(a, b):\n",
        "  return (2 * a + 3 * b) ** 2"
      ],
      "metadata": {
        "id": "eC8-6D3szHBg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute(a, b)"
      ],
      "metadata": {
        "id": "jZfbwJvazUR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a87fbf-8f21-45f4-de77-d6c2e771f04a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 8), dtype=float32, numpy=\n",
              "array([[7978.3716 ,  613.69543, 1370.2797 , 5507.004  , 3577.0085 ,\n",
              "        1100.6749 , 1908.7783 ,  938.38605],\n",
              "       [3835.6199 ,  189.35634, 1787.7913 , 2878.7053 , 4092.2202 ,\n",
              "        5263.0137 , 1011.672  , 1863.6316 ],\n",
              "       [4194.3066 , 1478.3016 , 1353.9016 , 4285.118  , 2688.7854 ,\n",
              "         690.8066 , 1469.7699 , 1753.723  ],\n",
              "       [3528.6697 , 3830.0618 , 3976.07   ,  363.5731 , 2065.1172 ,\n",
              "        5099.134  , 3478.9976 , 1947.6564 ],\n",
              "       [2916.9888 , 3355.6406 , 1536.6302 , 5883.973  , 1812.0632 ,\n",
              "        5500.143  ,  558.1455 ,  409.08298]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute(2, 3)"
      ],
      "metadata": {
        "id": "wVG3_0J6zhZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5045058a-ba76-4281-ce5c-a8b0e0badae5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=169>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute(tf.constant([2]), tf.constant([3]))"
      ],
      "metadata": {
        "id": "i5drq-otzjTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab6b920-32be-42ea-abb1-4eba3f3bf561"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([169], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the value\n",
        "compute(tf.constant([2]), tf.constant([3])).numpy()[0]"
      ],
      "metadata": {
        "id": "ZQHqXzUF0KB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d491875-80c1-4ae1-e321-4b8e9b880ec6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "169"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute(a, b) / 100000"
      ],
      "metadata": {
        "id": "S2D2vyzA0PSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef884e0-9bcf-41e9-9ba3-3ba0330ab8aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 8), dtype=float32, numpy=\n",
              "array([[0.07978372, 0.00613695, 0.0137028 , 0.05507004, 0.03577008,\n",
              "        0.01100675, 0.01908778, 0.00938386],\n",
              "       [0.0383562 , 0.00189356, 0.01787791, 0.02878705, 0.0409222 ,\n",
              "        0.05263014, 0.01011672, 0.01863632],\n",
              "       [0.04194307, 0.01478302, 0.01353902, 0.04285118, 0.02688785,\n",
              "        0.00690807, 0.0146977 , 0.01753723],\n",
              "       [0.0352867 , 0.03830062, 0.0397607 , 0.00363573, 0.02065117,\n",
              "        0.05099134, 0.03478998, 0.01947656],\n",
              "       [0.02916989, 0.03355641, 0.0153663 , 0.05883973, 0.01812063,\n",
              "        0.05500143, 0.00558146, 0.00409083]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(5.0)"
      ],
      "metadata": {
        "id": "5_c42jLt07cg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  y = x ** 2\n",
        "  grad_y = tape.gradient(y, x)"
      ],
      "metadata": {
        "id": "x9_7rOV610Uo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_y"
      ],
      "metadata": {
        "id": "mhiog0Gw1_-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3cd749-b143-4da2-e912-391c6b66c910"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=10.0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  y = tf.sin(x ** 2)\n",
        "  grad_y = tape.gradient(y, x)"
      ],
      "metadata": {
        "id": "OHGQADM12gRG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_y"
      ],
      "metadata": {
        "id": "cwsFc0cu21oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497c4970-d414-42fe-a2f5-26548b495815"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=9.912028>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iris dataset"
      ],
      "metadata": {
        "id": "ld9N4VAr5ndQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic regression"
      ],
      "metadata": {
        "id": "lW8fYiYKQXUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_iris().data, load_iris().target"
      ],
      "metadata": {
        "id": "kO9cLS105s2k"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_X = X.shape[1]\n",
        "num_classes = len(set(y))\n",
        "num_X, num_classes"
      ],
      "metadata": {
        "id": "xA1WbofT8dcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38175c3a-f017-4fb7-afa6-feb9c9304ae1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model\n",
        "logistic_regression = Sequential([\n",
        "    Input(num_X),\n",
        "    Dense(num_classes, activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "aQZKb3HY58Nw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression.summary()"
      ],
      "metadata": {
        "id": "kUqn4ozn8zdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5796124-5246-4881-e9d0-2638bb96dc3f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 3)                 15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15 (60.00 Byte)\n",
            "Trainable params: 15 (60.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding loss function\n",
        "logistic_regression.compile(optimizer = 'sgd', loss = 'sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "OSMUZkoNHaCX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression.fit(X, y, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTW0a_TWKFao",
        "outputId": "3132bd89-8df8-4a6f-d250-8d0f68283281"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.9218\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.3712\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.1234\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.0279\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.9699\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9085\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8464\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7927\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7293\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6731\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6176\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5631\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5126\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4706\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4145\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3733\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3260\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2845\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2411\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2055\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1671\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1344\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1008\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0759\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0392\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0137\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9899\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9688\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9397\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9206\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9065\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8848\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8671\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8499\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8357\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8199\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8063\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7977\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7822\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7706\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7604\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7495\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7412\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7335\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7252\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7165\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7090\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7006\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6923\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6838\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6788\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6771\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6652\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6622\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6530\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6522\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6466\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6381\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6344\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6311\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6237\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6209\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6170\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6129\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6071\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6046\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6005\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5977\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5941\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5889\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5926\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5842\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5846\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5785\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5735\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5717\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5696\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5647\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5636\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5583\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5590\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5547\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5539\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5521\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5455\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5485\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5496\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5451\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5413\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5346\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5316\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5329\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5314\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5253\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5276\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5249\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5199\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5198\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5164\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c045c509660>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jULWy7w_OgGh",
        "outputId": "cc892733-476b-43b8-a8b5-2844e6eb487d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.86211705, 0.11874901, 0.01913395],\n",
              "       [0.8030907 , 0.15814047, 0.03876891],\n",
              "       [0.83757144, 0.13655803, 0.02587061],\n",
              "       [0.7937025 , 0.16905898, 0.03723851],\n",
              "       [0.86937344, 0.11414175, 0.0164848 ],\n",
              "       [0.8572959 , 0.12600923, 0.01669492],\n",
              "       [0.8370502 , 0.1403557 , 0.02259402],\n",
              "       [0.8378429 , 0.13739778, 0.0247593 ],\n",
              "       [0.7784966 , 0.17788897, 0.04361441],\n",
              "       [0.80774254, 0.15594031, 0.03631712],\n",
              "       [0.87346196, 0.11028028, 0.01625778],\n",
              "       [0.8198631 , 0.15257597, 0.02756092],\n",
              "       [0.80848193, 0.15432836, 0.03718965],\n",
              "       [0.8418237 , 0.13227932, 0.02589692],\n",
              "       [0.9246712 , 0.0680273 , 0.00730146],\n",
              "       [0.91671324, 0.07697139, 0.00631539],\n",
              "       [0.89857286, 0.09109581, 0.01033139],\n",
              "       [0.856342  , 0.12374052, 0.01991751],\n",
              "       [0.8591456 , 0.12211445, 0.01873992],\n",
              "       [0.87170106, 0.11381326, 0.01448564],\n",
              "       [0.8174592 , 0.15092261, 0.0316182 ],\n",
              "       [0.857274  , 0.12527648, 0.01744947],\n",
              "       [0.9025412 , 0.08741197, 0.01004674],\n",
              "       [0.774605  , 0.18526317, 0.04013186],\n",
              "       [0.77172434, 0.18975878, 0.03851684],\n",
              "       [0.7715631 , 0.17989334, 0.04854363],\n",
              "       [0.8096752 , 0.16034722, 0.02997763],\n",
              "       [0.85180175, 0.12660067, 0.02159766],\n",
              "       [0.8543468 , 0.12345925, 0.0221939 ],\n",
              "       [0.79284483, 0.17079633, 0.03635877],\n",
              "       [0.7814452 , 0.17660968, 0.04194505],\n",
              "       [0.83237404, 0.14045762, 0.0271684 ],\n",
              "       [0.90452516, 0.08689103, 0.00858381],\n",
              "       [0.9179887 , 0.07513514, 0.00687614],\n",
              "       [0.8002262 , 0.16206868, 0.03770515],\n",
              "       [0.85582185, 0.12090743, 0.0232707 ],\n",
              "       [0.87956065, 0.10322998, 0.0172093 ],\n",
              "       [0.87310266, 0.11112213, 0.01577523],\n",
              "       [0.80827856, 0.1577604 , 0.0339609 ],\n",
              "       [0.8397359 , 0.13541345, 0.02485057],\n",
              "       [0.866345  , 0.11601709, 0.01763798],\n",
              "       [0.69050634, 0.21876274, 0.09073094],\n",
              "       [0.83179   , 0.14262746, 0.02558264],\n",
              "       [0.80705667, 0.16486667, 0.0280767 ],\n",
              "       [0.81427634, 0.16170539, 0.02401815],\n",
              "       [0.79327625, 0.16664864, 0.04007514],\n",
              "       [0.86605585, 0.11827743, 0.01566675],\n",
              "       [0.82160807, 0.14948228, 0.02890972],\n",
              "       [0.8718527 , 0.11194252, 0.01620475],\n",
              "       [0.84053326, 0.13401832, 0.02544849],\n",
              "       [0.09466546, 0.4380445 , 0.46728995],\n",
              "       [0.10638048, 0.4743671 , 0.41925237],\n",
              "       [0.06579176, 0.41723827, 0.51697   ],\n",
              "       [0.07261917, 0.385336  , 0.54204476],\n",
              "       [0.06395151, 0.39868668, 0.53736186],\n",
              "       [0.07387748, 0.43625847, 0.489864  ],\n",
              "       [0.09123069, 0.48981485, 0.41895443],\n",
              "       [0.17620918, 0.4382856 , 0.3855052 ],\n",
              "       [0.07826968, 0.40864953, 0.5130807 ],\n",
              "       [0.11394515, 0.46919435, 0.41686058],\n",
              "       [0.09864744, 0.37642163, 0.524931  ],\n",
              "       [0.11391003, 0.4759455 , 0.4101445 ],\n",
              "       [0.07608822, 0.3430334 , 0.5808783 ],\n",
              "       [0.06528039, 0.42673925, 0.50798047],\n",
              "       [0.19337997, 0.47188163, 0.3347384 ],\n",
              "       [0.11364851, 0.44659457, 0.43975684],\n",
              "       [0.08244626, 0.47869098, 0.43886286],\n",
              "       [0.11517541, 0.42627317, 0.4585513 ],\n",
              "       [0.03507434, 0.30908304, 0.6558426 ],\n",
              "       [0.10913376, 0.4142558 , 0.47661048],\n",
              "       [0.06629058, 0.49044716, 0.44326225],\n",
              "       [0.12623635, 0.43809265, 0.43567097],\n",
              "       [0.0320427 , 0.33149117, 0.6364662 ],\n",
              "       [0.06402552, 0.4057468 , 0.5302276 ],\n",
              "       [0.10538204, 0.43065083, 0.46396706],\n",
              "       [0.10225197, 0.4359565 , 0.46179155],\n",
              "       [0.05469456, 0.3721288 , 0.57317656],\n",
              "       [0.04779177, 0.40384895, 0.54835933],\n",
              "       [0.07663472, 0.44385532, 0.47951   ],\n",
              "       [0.18490353, 0.42530993, 0.3897864 ],\n",
              "       [0.10844543, 0.40701532, 0.4845393 ],\n",
              "       [0.1250366 , 0.40766573, 0.46729773],\n",
              "       [0.12915817, 0.43690678, 0.43393508],\n",
              "       [0.03046911, 0.36788642, 0.6016444 ],\n",
              "       [0.08121862, 0.4876813 , 0.4311    ],\n",
              "       [0.1190262 , 0.5231675 , 0.35780627],\n",
              "       [0.08020936, 0.43688843, 0.4829022 ],\n",
              "       [0.04875015, 0.32787365, 0.6233762 ],\n",
              "       [0.1333263 , 0.48514527, 0.38152847],\n",
              "       [0.08988363, 0.4190072 , 0.49110907],\n",
              "       [0.06852124, 0.4137786 , 0.5177002 ],\n",
              "       [0.08051752, 0.44958854, 0.4698939 ],\n",
              "       [0.10593172, 0.4195158 , 0.4745525 ],\n",
              "       [0.16206913, 0.42291653, 0.41501427],\n",
              "       [0.09040241, 0.4383678 , 0.47122967],\n",
              "       [0.1271896 , 0.47603652, 0.3967739 ],\n",
              "       [0.11098672, 0.4649264 , 0.42408693],\n",
              "       [0.10398844, 0.43948072, 0.45653075],\n",
              "       [0.24302419, 0.4349752 , 0.32200056],\n",
              "       [0.11126235, 0.4531621 , 0.43557554],\n",
              "       [0.01482792, 0.40972325, 0.5754488 ],\n",
              "       [0.02626191, 0.37859848, 0.59513944],\n",
              "       [0.01457236, 0.32165602, 0.6637716 ],\n",
              "       [0.02021707, 0.35701826, 0.6227647 ],\n",
              "       [0.01519093, 0.35457164, 0.6302374 ],\n",
              "       [0.00644169, 0.25043368, 0.7431246 ],\n",
              "       [0.04244299, 0.42169344, 0.5358635 ],\n",
              "       [0.00924484, 0.26437014, 0.72638506],\n",
              "       [0.00980354, 0.25253493, 0.7376615 ],\n",
              "       [0.01978336, 0.42460847, 0.5556082 ],\n",
              "       [0.04603477, 0.44774905, 0.50621617],\n",
              "       [0.02153343, 0.33794102, 0.6405255 ],\n",
              "       [0.02283628, 0.36564094, 0.6115228 ],\n",
              "       [0.02204944, 0.35177508, 0.6261755 ],\n",
              "       [0.02343243, 0.40230098, 0.5742666 ],\n",
              "       [0.03205334, 0.44074377, 0.5272029 ],\n",
              "       [0.0258042 , 0.376367  , 0.59782875],\n",
              "       [0.01495461, 0.39202413, 0.59302133],\n",
              "       [0.00235529, 0.16964117, 0.8280035 ],\n",
              "       [0.01940744, 0.28138968, 0.69920284],\n",
              "       [0.02110308, 0.38680756, 0.5920894 ],\n",
              "       [0.03479102, 0.42357463, 0.5416344 ],\n",
              "       [0.00458045, 0.20848805, 0.78693146],\n",
              "       [0.03542671, 0.3717314 , 0.59284186],\n",
              "       [0.02568075, 0.4145981 , 0.5597212 ],\n",
              "       [0.01914964, 0.34706125, 0.63378924],\n",
              "       [0.04415576, 0.40246537, 0.55337876],\n",
              "       [0.04905272, 0.4383151 , 0.51263213],\n",
              "       [0.0156528 , 0.33480567, 0.6495415 ],\n",
              "       [0.0207463 , 0.32297453, 0.6562791 ],\n",
              "       [0.00988209, 0.25830057, 0.7318173 ],\n",
              "       [0.023353  , 0.40708768, 0.5695594 ],\n",
              "       [0.01494179, 0.33527744, 0.6497808 ],\n",
              "       [0.0364337 , 0.37371305, 0.58985317],\n",
              "       [0.01667353, 0.30532566, 0.6780008 ],\n",
              "       [0.01074029, 0.28402394, 0.70523584],\n",
              "       [0.02722271, 0.46354362, 0.5092337 ],\n",
              "       [0.0288216 , 0.40069455, 0.57048386],\n",
              "       [0.05426271, 0.44935682, 0.49638042],\n",
              "       [0.0289349 , 0.38913321, 0.58193177],\n",
              "       [0.01985158, 0.3838252 , 0.5963233 ],\n",
              "       [0.03692957, 0.41367307, 0.5493974 ],\n",
              "       [0.02626191, 0.37859848, 0.59513944],\n",
              "       [0.01669249, 0.37465525, 0.6086522 ],\n",
              "       [0.02134851, 0.417437  , 0.5612145 ],\n",
              "       [0.02911835, 0.3949129 , 0.5759688 ],\n",
              "       [0.02376413, 0.3267383 , 0.64949757],\n",
              "       [0.03301834, 0.4011282 , 0.5658534 ],\n",
              "       [0.03520553, 0.4826186 , 0.48217586],\n",
              "       [0.03892662, 0.43314114, 0.52793217]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression"
      ],
      "metadata": {
        "id": "HTFpl1LDsOeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_for_regression = X[:,:-1]\n",
        "y_for_regression = X[:, -1]"
      ],
      "metadata": {
        "id": "MFRS-PV7uECf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regression = Sequential([\n",
        "    Input(X_for_regression.shape[1]),\n",
        "    Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "e0bRBqP8sSNc"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regression.compile(optimizer = 'sgd', loss = 'mse')"
      ],
      "metadata": {
        "id": "AtYM0-MXs3M6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regression.fit(X_for_regression, y_for_regression, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJikE9geu65y",
        "outputId": "7f14d55d-f109-490c-801b-669dedc4f4cb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1460\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1321\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1459\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1376\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1321\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1335\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1277\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1248\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1227\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1243\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1252\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1223\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1356\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1313\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1245\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1187\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1170\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1171\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1177\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1110\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1144\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1174\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1305\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1081\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1083\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1086\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1049\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1064\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1029\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1023\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1012\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1010\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1074\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1110\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1071\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1057\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0994\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1002\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1027\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1003\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1027\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0977\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0967\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0982\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0970\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1037\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0987\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0925\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1073\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0886\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0876\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0867\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0997\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0861\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0875\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1037\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0889\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0851\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0816\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0925\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0862\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0809\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0939\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0879\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0811\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0817\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0835\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0804\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0779\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0787\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0771\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0781\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0801\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0887\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0731\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0763\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0741\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0737\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0776\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0772\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0739\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0718\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0713\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0720\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0732\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0821\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0922\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0756\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0758\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0690\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0687\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0685\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0691\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0751\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0706\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0652\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c044cb2c730>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regression.predict(X_for_regression)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gKd2_0XvCoD",
        "outputId": "e2b58385-7a7c-4c20-c3bd-aa0d204f61cc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24009429],\n",
              "       [0.35459617],\n",
              "       [0.23514886],\n",
              "       [0.31278208],\n",
              "       [0.19629322],\n",
              "       [0.2649288 ],\n",
              "       [0.19432102],\n",
              "       [0.28588226],\n",
              "       [0.3088229 ],\n",
              "       [0.35756925],\n",
              "       [0.2589825 ],\n",
              "       [0.2878693 ],\n",
              "       [0.3396671 ],\n",
              "       [0.16948663],\n",
              "       [0.13654752],\n",
              "       [0.10166578],\n",
              "       [0.1375484 ],\n",
              "       [0.24009429],\n",
              "       [0.3385879 ],\n",
              "       [0.18532346],\n",
              "       [0.40928867],\n",
              "       [0.21419536],\n",
              "       [0.00919668],\n",
              "       [0.39337352],\n",
              "       [0.38340458],\n",
              "       [0.43321535],\n",
              "       [0.31772736],\n",
              "       [0.28686836],\n",
              "       [0.28389522],\n",
              "       [0.33068416],\n",
              "       [0.37448528],\n",
              "       [0.3455985 ],\n",
              "       [0.11363642],\n",
              "       [0.0977066 ],\n",
              "       [0.35756925],\n",
              "       [0.248091  ],\n",
              "       [0.26796532],\n",
              "       [0.18136422],\n",
              "       [0.24810584],\n",
              "       [0.30081132],\n",
              "       [0.19332011],\n",
              "       [0.46513873],\n",
              "       [0.19036181],\n",
              "       [0.2888554 ],\n",
              "       [0.31270382],\n",
              "       [0.3396671 ],\n",
              "       [0.21716855],\n",
              "       [0.25206497],\n",
              "       [0.24405347],\n",
              "       [0.28290918],\n",
              "       [1.66125   ],\n",
              "       [1.5079857 ],\n",
              "       [1.7388833 ],\n",
              "       [1.4742466 ],\n",
              "       [1.6702478 ],\n",
              "       [1.5189704 ],\n",
              "       [1.5278747 ],\n",
              "       [1.1328847 ],\n",
              "       [1.6563047 ],\n",
              "       [1.2821264 ],\n",
              "       [1.3269919 ],\n",
              "       [1.395549  ],\n",
              "       [1.5777639 ],\n",
              "       [1.6135045 ],\n",
              "       [1.1885635 ],\n",
              "       [1.5497997 ],\n",
              "       [1.4462973 ],\n",
              "       [1.435391  ],\n",
              "       [1.7668475 ],\n",
              "       [1.3995866 ],\n",
              "       [1.5288758 ],\n",
              "       [1.419461  ],\n",
              "       [1.8225409 ],\n",
              "       [1.6423765 ],\n",
              "       [1.5309116 ],\n",
              "       [1.5637426 ],\n",
              "       [1.7787253 ],\n",
              "       [1.7697423 ],\n",
              "       [1.5348855 ],\n",
              "       [1.2582633 ],\n",
              "       [1.3816844 ],\n",
              "       [1.3498393 ],\n",
              "       [1.3717008 ],\n",
              "       [1.7837    ],\n",
              "       [1.4164392 ],\n",
              "       [1.3905255 ],\n",
              "       [1.6453348 ],\n",
              "       [1.7210594 ],\n",
              "       [1.3189169 ],\n",
              "       [1.4165026 ],\n",
              "       [1.5150111 ],\n",
              "       [1.5527877 ],\n",
              "       [1.4324179 ],\n",
              "       [1.1766858 ],\n",
              "       [1.4373778 ],\n",
              "       [1.365691  ],\n",
              "       [1.3945628 ],\n",
              "       [1.5010535 ],\n",
              "       [1.0383356 ],\n",
              "       [1.39159   ],\n",
              "       [1.941861  ],\n",
              "       [1.7538419 ],\n",
              "       [2.1160645 ],\n",
              "       [1.9299686 ],\n",
              "       [1.994645  ],\n",
              "       [2.4136252 ],\n",
              "       [1.486154  ],\n",
              "       [2.3021748 ],\n",
              "       [2.168863  ],\n",
              "       [2.0214515 ],\n",
              "       [1.7139853 ],\n",
              "       [1.9071065 ],\n",
              "       [1.9438968 ],\n",
              "       [1.7648116 ],\n",
              "       [1.72497   ],\n",
              "       [1.7627465 ],\n",
              "       [1.8991097 ],\n",
              "       [2.2294235 ],\n",
              "       [2.6395774 ],\n",
              "       [1.8962148 ],\n",
              "       [1.9647719 ],\n",
              "       [1.6314217 ],\n",
              "       [2.5181434 ],\n",
              "       [1.7647969 ],\n",
              "       [1.9060417 ],\n",
              "       [2.1050944 ],\n",
              "       [1.6891509 ],\n",
              "       [1.6483229 ],\n",
              "       [1.9737697 ],\n",
              "       [2.0991483 ],\n",
              "       [2.2822857 ],\n",
              "       [2.1637464 ],\n",
              "       [1.9737697 ],\n",
              "       [1.7996151 ],\n",
              "       [1.9867264 ],\n",
              "       [2.2693288 ],\n",
              "       [1.7856086 ],\n",
              "       [1.8553087 ],\n",
              "       [1.6015489 ],\n",
              "       [1.8981087 ],\n",
              "       [1.9319408 ],\n",
              "       [1.8025734 ],\n",
              "       [1.7538419 ],\n",
              "       [2.013533  ],\n",
              "       [1.9060417 ],\n",
              "       [1.8334323 ],\n",
              "       [1.854386  ],\n",
              "       [1.8035742 ],\n",
              "       [1.7069894 ],\n",
              "       [1.682155  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}